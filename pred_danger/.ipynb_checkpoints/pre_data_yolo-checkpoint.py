import os
import json
import shutil
from pathlib import Path
from tqdm import tqdm
import random
import numpy as np
import pandas as pd # âš ï¸ 'pd' is not defined ì˜¤ë¥˜ í•´ê²°

# ==========================================================
# ì„¤ì •ê°’
# ==========================================================
# 1. ì›ë³¸ CARLA ë°ì´í„°ê°€ ìˆëŠ” ìµœìƒìœ„ í´ë” ê²½ë¡œ
BASE_DATA_DIR = Path("/run/user/1000/gvfs/smb-share:server=10.10.14.211,share=carla_data/_output_extracted")
# 2. ìµœì¢… YOLO ë°ì´í„°ì…‹ì´ ìƒì„±ë  í´ë” ì´ë¦„
OUTPUT_DIR = Path("./yolo_carla_dataset")
# 3. í´ë˜ìŠ¤ ì •ì˜ (ëª¨ë“  ì°¨ëŸ‰ì„ 'vehicle' í•˜ë‚˜ë¡œ í†µì¼)
CLASS_MAPPING = {"vehicle": 0}
CLASS_NAMES = list(CLASS_MAPPING.keys())

# 4. PatchTSTì™€ ë™ì¼í•œ ìœˆë„ìš° í¬ê¸° (ì‚¬ê³  ë°œìƒ ì „ ëª‡ í”„ë ˆì„ì„ 'ì¤‘ìš”'í•˜ê²Œ ë³¼ ê²ƒì¸ê°€)
SEQ_LEN = 60
PRED_HORIZON = 60
WINDOW_SIZE = SEQ_LEN + PRED_HORIZON

# 5. ë°ì´í„° ë¶„í•  ë° ìƒ˜í”Œë§ ë¹„ìœ¨
TRAIN_RATIO = 0.8
VALID_RATIO = 0.1
# Negative ìƒ˜í”Œì„ Positive ìƒ˜í”Œ ìˆ˜ì˜ Në°°ë§Œí¼ ì¶”ì¶œ (ì˜ˆ: 2.0ì€ 2ë°°)
NEGATIVE_SAMPLING_RATIO = 2.0 

# ==========================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================================
def convert_bbox_to_yolo(bbox):
    """CARLA bbox [xmin, ymin, xmax, ymax]ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    x_min, y_min, x_max, y_max = bbox
    width = x_max - x_min
    height = y_max - y_min
    x_center = x_min + (width / 2)
    y_center = y_min + (height / 2)
    return x_center, y_center, width, height

# ==========================================================
# ë©”ì¸ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# ==========================================================
def process_data():
    if OUTPUT_DIR.exists():
        print(f"ê²½ê³ : ê¸°ì¡´ '{OUTPUT_DIR}' í´ë”ë¥¼ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.")
        shutil.rmtree(OUTPUT_DIR)
        
    vehicle_class_id = CLASS_MAPPING["vehicle"]

    print("â¡ï¸ STEP 1: ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶„ì„í•˜ì—¬ 'ì‚¬ê³  ì§ì „' ì¤‘ìš” êµ¬ê°„ì„ ì°¾ìŠµë‹ˆë‹¤...")
    important_frames = set()
    
    scenario_dirs = [d for d in BASE_DATA_DIR.iterdir() if d.is_dir()]

    for scenario_dir in tqdm(scenario_dirs, desc="Finding collision windows"):
        label_dir = scenario_dir / "ground_truth_labels"
        if not label_dir.exists(): continue
        
        try:
            json_files = list(label_dir.glob("*.json"))
            if not json_files: continue
            df_for_scan = pd.DataFrame([json.load(open(f)) for f in json_files])
        except (json.JSONDecodeError, ValueError) as e:
            print(f"ê²½ê³ : {scenario_dir.name} ì—ì„œ JSON íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜({e})ê°€ ë°œìƒí•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        if 'vehicles' not in df_for_scan.columns: continue

        all_vehicles_data = []
        for index, row in df_for_scan.iterrows():
            frame_id = row.get('frame_id')
            if frame_id is None: continue
            
            vehicles_dict = row.get('vehicles')
            if isinstance(vehicles_dict, dict):
                for vehicle_id, v_info in vehicles_dict.items():
                    all_vehicles_data.append({
                        'frame_id': frame_id, 
                        'vehicle_id': int(vehicle_id), 
                        'label': v_info.get('label', 0)
                    })
        
        if not all_vehicles_data: continue
        
        df_labels = pd.DataFrame(all_vehicles_data)

        for vehicle_id in df_labels['vehicle_id'].unique():
            v_df = df_labels[df_labels['vehicle_id'] == vehicle_id].sort_values('frame_id')
            collision_frames = v_df[v_df['label'] == 1]['frame_id'].tolist()
            
            for frame in collision_frames:
                # âœ¨âœ¨âœ¨ ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„! âœ¨âœ¨âœ¨
                # frame ë³€ìˆ˜ë¥¼ int()ë¡œ ê°ì‹¸ì„œ ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
                int_frame = int(frame)
                for i in range(int_frame - WINDOW_SIZE + 1, int_frame + 1):
                # âœ¨âœ¨âœ¨ ìˆ˜ì • ë âœ¨âœ¨âœ¨
                    if i >= 0:
                        important_frames.add((str(scenario_dir), str(i).zfill(6)))

    print(f"âœ… ì´ {len(important_frames)}ê°œì˜ í”„ë ˆì„ì„ ì¤‘ìš” êµ¬ê°„ìœ¼ë¡œ ì‹ë³„í–ˆìŠµë‹ˆë‹¤.")

    # ... (ì´í•˜ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼í•©ë‹ˆë‹¤) ...

    print("\nâ¡ï¸ STEP 2: ì´ë¯¸ì§€-ë¼ë²¨ ìŒì„ ìˆ˜ì§‘í•˜ê³  ì¤‘ìš”/ì¼ë°˜ ë°ì´í„°ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤...")
    positive_pairs = []
    negative_pairs = []

    for scenario_dir in tqdm(scenario_dirs, desc="Collecting data pairs"):
        label_dir = scenario_dir / "ground_truth_labels"
        front_img_dir = scenario_dir / "Front"
        rear_img_dir = scenario_dir / "Rear"
        
        if not label_dir.exists(): continue

        for json_path in label_dir.glob("*.json"):
            frame_id_str = json_path.stem
            
            with open(json_path, 'r') as f: data = json.load(f)

            def create_pair(img_path, bbox_key):
                if img_path.exists():
                    labels = []
                    for v_info in data.get('vehicles', {}).values():
                        v_data = v_info.get('vehicle_data', {})
                        if v_data.get(bbox_key):
                            yolo_bbox = convert_bbox_to_yolo(v_data[bbox_key])
                            labels.append(f"{vehicle_class_id} {' '.join(map(str, yolo_bbox))}")
                    if labels:
                        return {"image": img_path, "labels": labels}
                return None

            pair_front = create_pair(front_img_dir / f"{frame_id_str}.png", 'bbox2d_front')
            pair_rear = create_pair(rear_img_dir / f"{frame_id_str}.png", 'bbox2d_rear')

            is_important = (str(scenario_dir), frame_id_str) in important_frames
            
            if pair_front: (positive_pairs if is_important else negative_pairs).append(pair_front)
            if pair_rear: (positive_pairs if is_important else negative_pairs).append(pair_rear)

    print("\nâ¡ï¸ STEP 3: ë°ì´í„°ì…‹ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ ìƒ˜í”Œë§ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
    
    if not positive_pairs:
        print("âŒ ì—ëŸ¬: ì¤‘ìš” êµ¬ê°„(Positive) ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    num_neg_samples = min(len(negative_pairs), int(len(positive_pairs) * NEGATIVE_SAMPLING_RATIO))
    sampled_negative_pairs = random.sample(negative_pairs, k=num_neg_samples)

    print(f"  - Positive (ì‚¬ê³  ì§ì „) ìƒ˜í”Œ: {len(positive_pairs)}ê°œ")
    print(f"  - Negative (ì•ˆì „) ìƒ˜í”Œ: {len(sampled_negative_pairs)}ê°œ (ì´ {len(negative_pairs)}ê°œ ì¤‘)")

    all_data_pairs = positive_pairs + sampled_negative_pairs
    random.shuffle(all_data_pairs)
    
    print(f"âœ… ì´ {len(all_data_pairs)}ê°œì˜ ì´ë¯¸ì§€ë¡œ ìµœì¢… ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.")
    
    print("\nâ¡ï¸ STEP 4: ë°ì´í„°ë¥¼ train/valid/test ì„¸íŠ¸ë¡œ ë¶„í• í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤...")
    train_count = int(len(all_data_pairs) * TRAIN_RATIO)
    valid_count = int(len(all_data_pairs) * VALID_RATIO)
    
    splits = {
        "train": all_data_pairs[:train_count],
        "valid": all_data_pairs[train_count : train_count + valid_count],
        "test": all_data_pairs[train_count + valid_count :]
    }

    for split_name, data_list in splits.items():
        img_dir = OUTPUT_DIR / split_name / "images"
        lbl_dir = OUTPUT_DIR / split_name / "labels"
        os.makedirs(img_dir, exist_ok=True); os.makedirs(lbl_dir, exist_ok=True)
        
        for item in tqdm(data_list, desc=f"Writing {split_name} set"):
            img_path = item["image"]
            labels = item["labels"]
            shutil.copy(img_path, img_dir / img_path.name)
            label_path = lbl_dir / f"{img_path.stem}.txt"
            with open(label_path, 'w') as f:
                f.write("\n".join(labels))

    print("\nâ¡ï¸ STEP 5: 'data.yaml' ì„¤ì • íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    yaml_content = f"""
train: {os.path.abspath(OUTPUT_DIR / 'train' / 'images')}
val: {os.path.abspath(OUTPUT_DIR / 'valid' / 'images')}
test: {os.path.abspath(OUTPUT_DIR / 'test' / 'images')}

nc: {len(CLASS_NAMES)}
names: {CLASS_NAMES}
"""
    with open(OUTPUT_DIR / "data.yaml", 'w') as f: f.write(yaml_content)
    print(f"\nğŸ‰ ëª¨ë“  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! '{OUTPUT_DIR}' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# ==========================================================
# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# ==========================================================
if __name__ == "__main__":
    process_data()